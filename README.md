# ComparaÃ§Ã£o de algorÃ­timos de Machine Learning ğŸ“Š

**Objetivo:** Comparar os resultados de algoritmos de Machine Learning com problemas de classificaÃ§Ã£o.

## Datasets utilizados ğŸ“‚

1. [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic) ğŸš¢
2. [Diabetes prediction dataset](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset) ğŸ’‰

## Algoritmos de ML utilizados ğŸ¤–

* Ãrvore de DecisÃ£o (gini e entropy)
* kNN (k igual a 5 e 10)
* MLP (escolher duas arquiteturas diferentes e variar o parÃ¢metro activation = {â€˜reluâ€™,â€™tanhâ€™}). â€œreluâ€ Ã© o valor default para o parÃ¢metro activation
* K-Means (K igual ao nÃºmero de classes existente no problema)

    Total: **9 algoritmos**

## Resultados dos treinamentos ğŸ“ˆ

*Porcentagens em mÃ©dia das prediÃ§Ãµes*

### Dataset - **Titanic** ğŸš¢

Modelo             |      AcurÃ¡cia
------------------ | ------------------
Tree (Gini)        |      77.75%
Tree (Entropy)     |      77.60%
kNN (k=5)          |      81.38%
kNN (k=10)         |      80.68%
MLP (ReLU)         |      79.14%
MLP (Tanh)         |      79.27%
MLP Large (ReLu)   |      81.24%
MLP Large (Tanh)   |      78.57%
K-Means            |      78.00%

### Dataset - **Diabetes** ğŸ’‰

Modelo             |      AcurÃ¡cia
------------------ | ------------------
Tree (Gini)        |      93.33
Tree (Entropy)     |      93.33
kNN (k=5)          |      89.33
kNN (k=10)         |      88.67
MLP (ReLU)         |      94.00
MLP (Tanh)         |      94.67
MLP Large (ReLu)   |      92.00
MLP Large (Tanh)   |      94.00
K-Means            |      88.

ğŸ“Œ *Este estudo proporciona insights valiosos sobre o desempenho de diferentes algoritmos em contextos distintos de classificaÃ§Ã£o!*